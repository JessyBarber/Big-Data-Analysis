{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDbJWoO1yO8e"
      },
      "source": [
        "# Image Classification with CNN - LeNet5 architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzQxqD6HyO8i"
      },
      "source": [
        "In this exercise, we will apply the LeNet5 algorithm to the Fashion MNIST dataset and improve your performances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFyVotRvyO8j"
      },
      "source": [
        "We will first download the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTHLyL1fyO8j",
        "outputId": "58a23a7d-5ea5-4fe0-8024-96adb022a692",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# TODO: Load the dataset\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# # # If your computer is slow, try to use a subset of data, e.g.\n",
        "# X_train = X_train[:10000]\n",
        "# y_train = y_train[:10000]\n",
        "# X_test = X_test[:2000]\n",
        "# y_test = y_test[:2000]\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8ShXIANyO8l"
      },
      "source": [
        "As you already know, this dataset contains 10 classes:\n",
        "* 0:\tT-shirt/top\n",
        "* 1:\tTrouser\n",
        "* 2:\tPullover\n",
        "* 3:\tDress\n",
        "* 4:\tCoat\n",
        "* 5:\tSandal\n",
        "* 6:\tShirt\n",
        "* 7:\tSneaker\n",
        "* 8:\tBag\n",
        "* 9:\tAnkle boot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BvNG0PbyO8l"
      },
      "source": [
        "You can have a look at some images if needed, even if you already know them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "lnjqgv-GyO8m",
        "outputId": "99e52ab2-02f6-4acd-c620-307492facb62",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# TODO: Explore the data, display some input images\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "label_class = ['top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
        "\n",
        "idx = np.random.randint(X_train.shape[0])\n",
        "\n",
        "plt.imshow(X_train[idx], cmap=\"gray_r\")\n",
        "plt.title(label_class[y_train[idx]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdYH6XW1yO8n"
      },
      "source": [
        "Make the data preparation and preprocessing: scale and reshape the data, put the labels to the good shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fjv8XMPByO8o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "403137e8-5aeb-4f57-c7a4-fa05aba5fc54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# TODO: Make the data preparation\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_cat = to_categorical(y_train, num_classes=10)\n",
        "y_test_cat = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "X_train_norm = X_train / 255\n",
        "X_test_norm = X_test / 255\n",
        "\n",
        "\n",
        "X_train_norm = X_train_norm.reshape(X_train_norm.shape[0], 28, 28, 1)\n",
        "X_test_norm = X_test_norm.reshape(X_test_norm.shape[0], 28, 28, 1)\n",
        "\n",
        "X_train_norm.shape #Should be (60000, 28, 28, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9LKzxR9yO8o"
      },
      "source": [
        "Now build the LeNet5 architecture. You can reuse the one of the course, or try to build it by yourself.\n",
        "\n",
        "The architecture is the following:\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1WteTU2FPIVMkBKmMxGpFm5OjsX-szTbB\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GKyMFlL6yO8o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18c84bb0-2089-4dee-c335-46da6f88db61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " C1 (Conv2D)                 (None, 26, 26, 6)         60        \n",
            "                                                                 \n",
            " S2 (MaxPooling2D)           (None, 13, 13, 6)         0         \n",
            "                                                                 \n",
            " C3 (Conv2D)                 (None, 11, 11, 16)        880       \n",
            "                                                                 \n",
            " S4 (MaxPooling2D)           (None, 5, 5, 16)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 400)               0         \n",
            "                                                                 \n",
            " C5 (Dense)                  (None, 120)               48120     \n",
            "                                                                 \n",
            " F6 (Dense)                  (None, 84)                10164     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 60,074\n",
            "Trainable params: 60,074\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# TODO: Build your model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import MaxPooling2D, Conv2D, Flatten, Dense\n",
        "\n",
        "\n",
        "def lenet5():\n",
        "    \n",
        "    model = Sequential()\n",
        "\n",
        "    # Layer C1\n",
        "    model.add(Conv2D(filters=6, name='C1', kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
        "    # Layer S2\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), name='S2'))\n",
        "    # Layer C3\n",
        "    model.add(Conv2D(filters=16, name='C3', kernel_size=(3, 3), activation='relu'))\n",
        "    # Layer S4\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), name='S4'))\n",
        "    # Before going into layer C5, we flatten our units\n",
        "    model.add(Flatten())\n",
        "    # Layer C5\n",
        "    model.add(Dense(120, activation='relu', name='C5'))\n",
        "    # Layer F6\n",
        "    model.add(Dense(84, activation='relu', name='F6'))\n",
        "    # Output layer\n",
        "    model.add(Dense(units=10, activation = 'softmax'))\n",
        "    \n",
        "    return model\n",
        "\n",
        "lenet5().summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1qBEauqyO8p"
      },
      "source": [
        "Now compile and fit your model on your training data. Since this is a multiclass classification, the loss is not `binary_crossentropy` anymore, but `categorical_crossentropy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPL3aKnyyO8p",
        "outputId": "29987454-31f7-4672-c08b-7dab120d607f",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "30/30 [==============================] - 13s 30ms/step - loss: 1.6237 - accuracy: 0.5339 - val_loss: 0.8899 - val_accuracy: 0.6936\n",
            "Epoch 2/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.7259 - accuracy: 0.7351 - val_loss: 0.6558 - val_accuracy: 0.7530\n",
            "Epoch 3/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.5885 - accuracy: 0.7757 - val_loss: 0.5749 - val_accuracy: 0.7846\n",
            "Epoch 4/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.5359 - accuracy: 0.7986 - val_loss: 0.5269 - val_accuracy: 0.8031\n",
            "Epoch 5/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.4949 - accuracy: 0.8172 - val_loss: 0.5032 - val_accuracy: 0.8105\n",
            "Epoch 6/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.4708 - accuracy: 0.8266 - val_loss: 0.4767 - val_accuracy: 0.8250\n",
            "Epoch 7/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.4503 - accuracy: 0.8357 - val_loss: 0.4683 - val_accuracy: 0.8290\n",
            "Epoch 8/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.4312 - accuracy: 0.8433 - val_loss: 0.4592 - val_accuracy: 0.8333\n",
            "Epoch 9/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.4203 - accuracy: 0.8477 - val_loss: 0.4529 - val_accuracy: 0.8347\n",
            "Epoch 10/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.4093 - accuracy: 0.8510 - val_loss: 0.4247 - val_accuracy: 0.8480\n",
            "Epoch 11/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.3949 - accuracy: 0.8562 - val_loss: 0.4123 - val_accuracy: 0.8516\n",
            "Epoch 12/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.3885 - accuracy: 0.8589 - val_loss: 0.4202 - val_accuracy: 0.8461\n",
            "Epoch 13/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.3818 - accuracy: 0.8617 - val_loss: 0.4010 - val_accuracy: 0.8567\n",
            "Epoch 14/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.3732 - accuracy: 0.8638 - val_loss: 0.3986 - val_accuracy: 0.8563\n",
            "Epoch 15/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.3673 - accuracy: 0.8662 - val_loss: 0.3937 - val_accuracy: 0.8553\n",
            "Epoch 16/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.3605 - accuracy: 0.8686 - val_loss: 0.3990 - val_accuracy: 0.8494\n",
            "Epoch 17/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.3551 - accuracy: 0.8706 - val_loss: 0.3777 - val_accuracy: 0.8647\n",
            "Epoch 18/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.3513 - accuracy: 0.8724 - val_loss: 0.3901 - val_accuracy: 0.8601\n",
            "Epoch 19/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.3500 - accuracy: 0.8727 - val_loss: 0.3729 - val_accuracy: 0.8655\n",
            "Epoch 20/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.3405 - accuracy: 0.8757 - val_loss: 0.3719 - val_accuracy: 0.8617\n",
            "Epoch 21/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.3400 - accuracy: 0.8763 - val_loss: 0.3610 - val_accuracy: 0.8684\n",
            "Epoch 22/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.3321 - accuracy: 0.8795 - val_loss: 0.3620 - val_accuracy: 0.8689\n",
            "Epoch 23/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.3320 - accuracy: 0.8788 - val_loss: 0.3583 - val_accuracy: 0.8704\n",
            "Epoch 24/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.3252 - accuracy: 0.8815 - val_loss: 0.3604 - val_accuracy: 0.8687\n",
            "Epoch 25/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.3277 - accuracy: 0.8796 - val_loss: 0.3556 - val_accuracy: 0.8722\n",
            "Epoch 26/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.3235 - accuracy: 0.8801 - val_loss: 0.3551 - val_accuracy: 0.8720\n",
            "Epoch 27/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.3145 - accuracy: 0.8852 - val_loss: 0.3444 - val_accuracy: 0.8750\n",
            "Epoch 28/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.3124 - accuracy: 0.8857 - val_loss: 0.3554 - val_accuracy: 0.8682\n",
            "Epoch 29/100\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.3161 - accuracy: 0.8835 - val_loss: 0.3670 - val_accuracy: 0.8691\n",
            "Epoch 30/100\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.3100 - accuracy: 0.8867 - val_loss: 0.3388 - val_accuracy: 0.8775\n",
            "Epoch 31/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.3058 - accuracy: 0.8878 - val_loss: 0.3433 - val_accuracy: 0.8761\n",
            "Epoch 32/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.3034 - accuracy: 0.8884 - val_loss: 0.3417 - val_accuracy: 0.8773\n",
            "Epoch 33/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.3008 - accuracy: 0.8904 - val_loss: 0.3361 - val_accuracy: 0.8779\n",
            "Epoch 34/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.2977 - accuracy: 0.8918 - val_loss: 0.3348 - val_accuracy: 0.8792\n",
            "Epoch 35/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.2993 - accuracy: 0.8907 - val_loss: 0.3334 - val_accuracy: 0.8797\n",
            "Epoch 36/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2978 - accuracy: 0.8913 - val_loss: 0.3416 - val_accuracy: 0.8751\n",
            "Epoch 37/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.2904 - accuracy: 0.8933 - val_loss: 0.3291 - val_accuracy: 0.8806\n",
            "Epoch 38/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.2890 - accuracy: 0.8944 - val_loss: 0.3363 - val_accuracy: 0.8786\n",
            "Epoch 39/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.2910 - accuracy: 0.8924 - val_loss: 0.3315 - val_accuracy: 0.8793\n",
            "Epoch 40/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.2829 - accuracy: 0.8967 - val_loss: 0.3233 - val_accuracy: 0.8830\n",
            "Epoch 41/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2827 - accuracy: 0.8971 - val_loss: 0.3325 - val_accuracy: 0.8791\n",
            "Epoch 42/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2856 - accuracy: 0.8955 - val_loss: 0.3211 - val_accuracy: 0.8843\n",
            "Epoch 43/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.2814 - accuracy: 0.8971 - val_loss: 0.3191 - val_accuracy: 0.8844\n",
            "Epoch 44/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.2758 - accuracy: 0.8996 - val_loss: 0.3167 - val_accuracy: 0.8856\n",
            "Epoch 45/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2786 - accuracy: 0.8989 - val_loss: 0.3195 - val_accuracy: 0.8847\n",
            "Epoch 46/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2723 - accuracy: 0.9007 - val_loss: 0.3281 - val_accuracy: 0.8833\n",
            "Epoch 47/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2747 - accuracy: 0.8996 - val_loss: 0.3232 - val_accuracy: 0.8850\n",
            "Epoch 48/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2688 - accuracy: 0.9019 - val_loss: 0.3292 - val_accuracy: 0.8758\n",
            "Epoch 49/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2729 - accuracy: 0.9000 - val_loss: 0.3153 - val_accuracy: 0.8857\n",
            "Epoch 50/100\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.2653 - accuracy: 0.9029 - val_loss: 0.3127 - val_accuracy: 0.8863\n",
            "Epoch 51/100\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.2642 - accuracy: 0.9032 - val_loss: 0.3244 - val_accuracy: 0.8828\n",
            "Epoch 52/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.2664 - accuracy: 0.9015 - val_loss: 0.3149 - val_accuracy: 0.8855\n",
            "Epoch 53/100\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.2628 - accuracy: 0.9036 - val_loss: 0.3205 - val_accuracy: 0.8838\n",
            "Epoch 54/100\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.2608 - accuracy: 0.9040 - val_loss: 0.3148 - val_accuracy: 0.8882\n",
            "Epoch 55/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.2608 - accuracy: 0.9040 - val_loss: 0.3055 - val_accuracy: 0.8897\n",
            "Epoch 56/100\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.2562 - accuracy: 0.9065 - val_loss: 0.3130 - val_accuracy: 0.8866\n",
            "Epoch 57/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.2577 - accuracy: 0.9043 - val_loss: 0.3166 - val_accuracy: 0.8855\n",
            "Epoch 58/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.2597 - accuracy: 0.9040 - val_loss: 0.3148 - val_accuracy: 0.8872\n",
            "Epoch 59/100\n",
            "30/30 [==============================] - 1s 23ms/step - loss: 0.2547 - accuracy: 0.9063 - val_loss: 0.3246 - val_accuracy: 0.8857\n",
            "Epoch 60/100\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.2523 - accuracy: 0.9074 - val_loss: 0.3125 - val_accuracy: 0.8891\n",
            "Epoch 61/100\n",
            "30/30 [==============================] - 1s 26ms/step - loss: 0.2497 - accuracy: 0.9081 - val_loss: 0.3179 - val_accuracy: 0.8869\n",
            "Epoch 62/100\n",
            "30/30 [==============================] - 1s 23ms/step - loss: 0.2550 - accuracy: 0.9058 - val_loss: 0.3044 - val_accuracy: 0.8918\n",
            "Epoch 63/100\n",
            "30/30 [==============================] - 1s 24ms/step - loss: 0.2472 - accuracy: 0.9089 - val_loss: 0.3158 - val_accuracy: 0.8876\n",
            "Epoch 64/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.2518 - accuracy: 0.9065 - val_loss: 0.3081 - val_accuracy: 0.8896\n",
            "Epoch 65/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2460 - accuracy: 0.9099 - val_loss: 0.3013 - val_accuracy: 0.8918\n",
            "Epoch 66/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2434 - accuracy: 0.9107 - val_loss: 0.3146 - val_accuracy: 0.8856\n",
            "Epoch 67/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2458 - accuracy: 0.9077 - val_loss: 0.3296 - val_accuracy: 0.8830\n",
            "Epoch 68/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2459 - accuracy: 0.9100 - val_loss: 0.3015 - val_accuracy: 0.8927\n",
            "Epoch 69/100\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.2423 - accuracy: 0.9111 - val_loss: 0.3026 - val_accuracy: 0.8930\n",
            "Epoch 70/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2386 - accuracy: 0.9119 - val_loss: 0.3019 - val_accuracy: 0.8909\n",
            "Epoch 71/100\n",
            "30/30 [==============================] - 1s 23ms/step - loss: 0.2373 - accuracy: 0.9122 - val_loss: 0.2950 - val_accuracy: 0.8940\n",
            "Epoch 72/100\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.2350 - accuracy: 0.9130 - val_loss: 0.3051 - val_accuracy: 0.8923\n",
            "Epoch 73/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2341 - accuracy: 0.9127 - val_loss: 0.3094 - val_accuracy: 0.8873\n",
            "Epoch 74/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2330 - accuracy: 0.9142 - val_loss: 0.2953 - val_accuracy: 0.8927\n",
            "Epoch 75/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2302 - accuracy: 0.9149 - val_loss: 0.3032 - val_accuracy: 0.8900\n",
            "Epoch 76/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2322 - accuracy: 0.9138 - val_loss: 0.3096 - val_accuracy: 0.8897\n",
            "Epoch 77/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2296 - accuracy: 0.9152 - val_loss: 0.3027 - val_accuracy: 0.8929\n",
            "Epoch 78/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2275 - accuracy: 0.9158 - val_loss: 0.2976 - val_accuracy: 0.8956\n",
            "Epoch 79/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2274 - accuracy: 0.9156 - val_loss: 0.3066 - val_accuracy: 0.8915\n",
            "Epoch 80/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2265 - accuracy: 0.9161 - val_loss: 0.3023 - val_accuracy: 0.8961\n",
            "Epoch 81/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2260 - accuracy: 0.9171 - val_loss: 0.3021 - val_accuracy: 0.8900\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f82d006a890>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# TODO: Compile and fit your model\n",
        "import os\n",
        "\n",
        "# os.environ['KMP_DUPLICATE_LIB_OK']='True' #https://stackoverflow.com/questions/53014306/error-15-initializing-libiomp5-dylib-but-found-libiomp5-dylib-already-initial\n",
        "\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "model = lenet5()\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define now our callbacks\n",
        "# callbacks = [EarlyStopping(monitor='val_loss', patience=10), TensorBoard(log_dir='./keras-logs', histogram_freq=0, write_graph=True, write_images=True)]\n",
        "callbacks = [EarlyStopping(monitor='val_loss', patience=10)]\n",
        "\n",
        "# Finally fit the model\n",
        "model.fit(x=X_train_norm, y=y_train_cat, validation_data=(X_test_norm, y_test_cat), epochs=100, batch_size=2048, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf-SqjjOyO8q"
      },
      "source": [
        "Have a look at the tensorboard and see if it gives a deeper understanding of your model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2FTj7TSyO8q"
      },
      "source": [
        "Compute then the accuracy of your model. Is it better than a regular MLP used before?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPjJoMQZyO8q",
        "outputId": "60d5a1bc-5d79-48d0-c033-bc8b9380f2b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on train with CNN: 0.9159\n",
            "accuracy on test with CNN: 0.89\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "batch_size = 1024\n",
        "y_pred_train = to_categorical(model.predict(X_train_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
        "y_pred_test = to_categorical(model.predict(X_test_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
        "\n",
        "print('accuracy on train with CNN:', accuracy_score(y_pred_train, y_train_cat))\n",
        "print('accuracy on test with CNN:', accuracy_score(y_pred_test, y_test_cat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vulsgHiyO8q"
      },
      "source": [
        "We will now add image augmentation to improve our results, especially we will try to reduce overfitting this way.\n",
        "\n",
        "To do so, you can use `ImageDataGenerator` from Keras that makes all the work for you (including rescaling), with the following parameter: \n",
        "* `horizontal_flip=True`\n",
        "\n",
        "For more info about how the `ImageDataGenerator` works, you can check out [this article](https://www.pyimagesearch.com/2019/07/08/keras-imagedatagenerator-and-data-augmentation/).\n",
        "\n",
        "Begin by creating an object `ImageDataGenerator` with this parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-19T11:58:37.442182Z",
          "start_time": "2020-08-19T11:58:37.438397Z"
        },
        "id": "pas-fMSIyO8q"
      },
      "outputs": [],
      "source": [
        "# TODO: Instantiate an ImageDataGenerator object\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(horizontal_flip=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7nCnu9syO8r"
      },
      "source": [
        "Finally, you can train your model using this generator, with the method `fit_generator` of your model and the method `flow` of your `ImageDataGenerator`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt6wXa3IyO8r",
        "outputId": "037f9bb6-0235-4a0a-fc12-406cb1ae5e8c",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58/58 [==============================] - 2s 34ms/step - loss: 0.4457 - accuracy: 0.8563 - val_loss: 0.3231 - val_accuracy: 0.8825\n",
            "Epoch 2/100\n",
            "58/58 [==============================] - 2s 34ms/step - loss: 0.2965 - accuracy: 0.8931 - val_loss: 0.3106 - val_accuracy: 0.8906\n",
            "Epoch 3/100\n",
            "58/58 [==============================] - 2s 33ms/step - loss: 0.2801 - accuracy: 0.8990 - val_loss: 0.3106 - val_accuracy: 0.8887\n",
            "Epoch 4/100\n",
            "58/58 [==============================] - 3s 43ms/step - loss: 0.2720 - accuracy: 0.9011 - val_loss: 0.3037 - val_accuracy: 0.8919\n",
            "Epoch 5/100\n",
            "58/58 [==============================] - 3s 45ms/step - loss: 0.2688 - accuracy: 0.9017 - val_loss: 0.3073 - val_accuracy: 0.8917\n",
            "Epoch 6/100\n",
            "58/58 [==============================] - 2s 32ms/step - loss: 0.2649 - accuracy: 0.9033 - val_loss: 0.3008 - val_accuracy: 0.8937\n",
            "Epoch 7/100\n",
            "58/58 [==============================] - 2s 42ms/step - loss: 0.2607 - accuracy: 0.9047 - val_loss: 0.3026 - val_accuracy: 0.8910\n",
            "Epoch 8/100\n",
            "58/58 [==============================] - 2s 35ms/step - loss: 0.2609 - accuracy: 0.9025 - val_loss: 0.3040 - val_accuracy: 0.8918\n",
            "Epoch 9/100\n",
            "58/58 [==============================] - 2s 33ms/step - loss: 0.2598 - accuracy: 0.9045 - val_loss: 0.2999 - val_accuracy: 0.8948\n",
            "Epoch 10/100\n",
            "58/58 [==============================] - 2s 42ms/step - loss: 0.2502 - accuracy: 0.9082 - val_loss: 0.2975 - val_accuracy: 0.8925\n",
            "Epoch 11/100\n",
            "58/58 [==============================] - 2s 32ms/step - loss: 0.2500 - accuracy: 0.9092 - val_loss: 0.2917 - val_accuracy: 0.8967\n",
            "Epoch 12/100\n",
            "58/58 [==============================] - 2s 42ms/step - loss: 0.2476 - accuracy: 0.9097 - val_loss: 0.2965 - val_accuracy: 0.8947\n",
            "Epoch 13/100\n",
            "58/58 [==============================] - 2s 32ms/step - loss: 0.2475 - accuracy: 0.9092 - val_loss: 0.2906 - val_accuracy: 0.8966\n",
            "Epoch 14/100\n",
            "58/58 [==============================] - 3s 44ms/step - loss: 0.2406 - accuracy: 0.9119 - val_loss: 0.2929 - val_accuracy: 0.8975\n",
            "Epoch 15/100\n",
            "58/58 [==============================] - 2s 33ms/step - loss: 0.2417 - accuracy: 0.9112 - val_loss: 0.2956 - val_accuracy: 0.8954\n",
            "Epoch 16/100\n",
            "58/58 [==============================] - 2s 43ms/step - loss: 0.2395 - accuracy: 0.9125 - val_loss: 0.2926 - val_accuracy: 0.8956\n",
            "Epoch 17/100\n",
            "58/58 [==============================] - 3s 45ms/step - loss: 0.2365 - accuracy: 0.9132 - val_loss: 0.3131 - val_accuracy: 0.8878\n",
            "Epoch 18/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.2390 - accuracy: 0.9123 - val_loss: 0.2925 - val_accuracy: 0.8936\n",
            "Epoch 19/100\n",
            "58/58 [==============================] - 3s 46ms/step - loss: 0.2360 - accuracy: 0.9125 - val_loss: 0.2836 - val_accuracy: 0.8983\n",
            "Epoch 20/100\n",
            "58/58 [==============================] - 3s 44ms/step - loss: 0.2330 - accuracy: 0.9149 - val_loss: 0.2959 - val_accuracy: 0.8964\n",
            "Epoch 21/100\n",
            "58/58 [==============================] - 3s 44ms/step - loss: 0.2314 - accuracy: 0.9150 - val_loss: 0.2877 - val_accuracy: 0.8963\n",
            "Epoch 22/100\n",
            "58/58 [==============================] - 3s 50ms/step - loss: 0.2278 - accuracy: 0.9168 - val_loss: 0.2936 - val_accuracy: 0.8929\n",
            "Epoch 23/100\n",
            "58/58 [==============================] - 3s 42ms/step - loss: 0.2276 - accuracy: 0.9165 - val_loss: 0.2928 - val_accuracy: 0.8935\n",
            "Epoch 24/100\n",
            "58/58 [==============================] - 2s 36ms/step - loss: 0.2265 - accuracy: 0.9164 - val_loss: 0.3013 - val_accuracy: 0.8910\n",
            "Epoch 25/100\n",
            "58/58 [==============================] - 3s 45ms/step - loss: 0.2219 - accuracy: 0.9182 - val_loss: 0.2871 - val_accuracy: 0.8975\n",
            "Epoch 26/100\n",
            "58/58 [==============================] - 3s 57ms/step - loss: 0.2215 - accuracy: 0.9184 - val_loss: 0.2932 - val_accuracy: 0.8995\n",
            "Epoch 27/100\n",
            "58/58 [==============================] - 2s 35ms/step - loss: 0.2205 - accuracy: 0.9180 - val_loss: 0.2878 - val_accuracy: 0.8967\n",
            "Epoch 28/100\n",
            "58/58 [==============================] - 2s 34ms/step - loss: 0.2203 - accuracy: 0.9184 - val_loss: 0.2822 - val_accuracy: 0.9010\n",
            "Epoch 29/100\n",
            "58/58 [==============================] - 2s 36ms/step - loss: 0.2211 - accuracy: 0.9172 - val_loss: 0.2941 - val_accuracy: 0.8974\n",
            "Epoch 30/100\n",
            "58/58 [==============================] - 2s 35ms/step - loss: 0.2170 - accuracy: 0.9204 - val_loss: 0.2861 - val_accuracy: 0.8963\n",
            "Epoch 31/100\n",
            "58/58 [==============================] - 2s 35ms/step - loss: 0.2152 - accuracy: 0.9204 - val_loss: 0.2951 - val_accuracy: 0.8944\n",
            "Epoch 32/100\n",
            "58/58 [==============================] - 3s 47ms/step - loss: 0.2154 - accuracy: 0.9199 - val_loss: 0.2937 - val_accuracy: 0.8939\n",
            "Epoch 33/100\n",
            "58/58 [==============================] - 3s 46ms/step - loss: 0.2100 - accuracy: 0.9221 - val_loss: 0.2950 - val_accuracy: 0.8971\n",
            "Epoch 34/100\n",
            "58/58 [==============================] - 2s 33ms/step - loss: 0.2112 - accuracy: 0.9208 - val_loss: 0.2938 - val_accuracy: 0.8972\n",
            "Epoch 35/100\n",
            "58/58 [==============================] - 3s 43ms/step - loss: 0.2095 - accuracy: 0.9231 - val_loss: 0.2820 - val_accuracy: 0.8975\n",
            "Epoch 36/100\n",
            "58/58 [==============================] - 2s 33ms/step - loss: 0.2105 - accuracy: 0.9215 - val_loss: 0.2929 - val_accuracy: 0.8962\n",
            "Epoch 37/100\n",
            "58/58 [==============================] - 3s 43ms/step - loss: 0.2084 - accuracy: 0.9230 - val_loss: 0.2901 - val_accuracy: 0.8952\n",
            "Epoch 38/100\n",
            "58/58 [==============================] - 2s 34ms/step - loss: 0.2069 - accuracy: 0.9236 - val_loss: 0.2910 - val_accuracy: 0.8957\n",
            "Epoch 39/100\n",
            "58/58 [==============================] - 2s 33ms/step - loss: 0.2059 - accuracy: 0.9240 - val_loss: 0.2902 - val_accuracy: 0.8963\n",
            "Epoch 40/100\n",
            "58/58 [==============================] - 3s 45ms/step - loss: 0.2055 - accuracy: 0.9238 - val_loss: 0.2847 - val_accuracy: 0.9002\n",
            "Epoch 41/100\n",
            "58/58 [==============================] - 3s 45ms/step - loss: 0.2008 - accuracy: 0.9256 - val_loss: 0.2890 - val_accuracy: 0.8975\n",
            "Epoch 42/100\n",
            "58/58 [==============================] - 2s 35ms/step - loss: 0.1990 - accuracy: 0.9261 - val_loss: 0.2851 - val_accuracy: 0.8991\n",
            "Epoch 43/100\n",
            "58/58 [==============================] - 3s 46ms/step - loss: 0.2018 - accuracy: 0.9246 - val_loss: 0.2977 - val_accuracy: 0.8974\n",
            "Epoch 44/100\n",
            "58/58 [==============================] - 2s 34ms/step - loss: 0.1985 - accuracy: 0.9268 - val_loss: 0.2959 - val_accuracy: 0.8932\n",
            "Epoch 45/100\n",
            "58/58 [==============================] - 3s 43ms/step - loss: 0.2004 - accuracy: 0.9244 - val_loss: 0.2831 - val_accuracy: 0.9006\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8264300a50>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# TODO: train your model\n",
        "batch_size = 1024\n",
        "model.fit_generator(datagen.flow(X_train_norm, y_train_cat, batch_size=batch_size),\n",
        "                    validation_data=(X_test_norm, y_test_cat), callbacks=callbacks,\n",
        "                    steps_per_epoch=len(X_train_norm) / batch_size, epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuzFke8pyO8r"
      },
      "source": [
        "Recompute the accuracy of your model, does it improve your performances with data augmentation?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsTm86tuyO8r",
        "outputId": "04abeac1-f8ce-40de-8d82-c8cade29ec26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on train with NN: 0.9324333333333333\n",
            "accuracy on test with NN: 0.9006\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "batch_size=1024\n",
        "y_pred_train = to_categorical(model.predict(X_train_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
        "y_pred_test = to_categorical(model.predict(X_test_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
        "\n",
        "print('accuracy on train with NN:', accuracy_score(y_pred_train, y_train_cat))\n",
        "print('accuracy on test with NN:', accuracy_score(y_pred_test, y_test_cat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOzkdGf7yO8s"
      },
      "source": [
        "You can now try to improve even more your results. For example, add more parameters to your `ImageDataGenerator`, play with some hyperparameters, and so on..."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "LeNet5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}